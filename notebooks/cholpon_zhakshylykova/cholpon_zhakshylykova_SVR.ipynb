{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support vector Regression (SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr, pointbiserialr\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset\n",
    "math = pd.read_csv(\"./student-mat.csv\", sep=';', header=0)\n",
    "por = pd.read_csv(\"./student-por.csv\", sep=';', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Correlations and P-values with Target Variable:\n",
      "G2: Correlation = 0.90, P-value = 7.626e-148\n",
      "G1: Correlation = 0.80, P-value = 9.001e-90\n",
      "failures: Correlation = 0.36, P-value = 1.466e-13\n",
      "Medu: Correlation = 0.22, P-value = 1.336e-05\n",
      "higher: Correlation = 0.18, P-value = 2.668e-04\n",
      "age: Correlation = 0.16, P-value = 1.271e-03\n",
      "Fedu: Correlation = 0.15, P-value = 2.380e-03\n",
      "goout: Correlation = 0.13, P-value = 8.229e-03\n",
      "romantic: Correlation = 0.13, P-value = 9.713e-03\n",
      "reason: Correlation = 0.12, P-value = 1.527e-02\n",
      "traveltime: Correlation = 0.12, P-value = 1.987e-02\n",
      "address: Correlation = 0.11, P-value = 3.563e-02\n",
      "sex: Correlation = 0.10, P-value = 3.987e-02\n",
      "Mjob: Correlation = 0.10, P-value = 4.259e-02\n",
      "paid: Correlation = 0.10, P-value = 4.277e-02\n",
      "internet: Correlation = 0.10, P-value = 5.048e-02\n",
      "studytime: Correlation = 0.10, P-value = 5.206e-02\n",
      "schoolsup: Correlation = 0.08, P-value = 1.004e-01\n",
      "famsize: Correlation = 0.08, P-value = 1.062e-01\n",
      "guardian: Correlation = 0.07, P-value = 1.643e-01\n",
      "health: Correlation = 0.06, P-value = 2.239e-01\n",
      "Pstatus: Correlation = 0.06, P-value = 2.501e-01\n",
      "Dalc: Correlation = 0.05, P-value = 2.785e-01\n",
      "Walc: Correlation = 0.05, P-value = 3.032e-01\n",
      "nursery: Correlation = 0.05, P-value = 3.066e-01\n",
      "famrel: Correlation = 0.05, P-value = 3.086e-01\n",
      "school: Correlation = 0.05, P-value = 3.722e-01\n",
      "Fjob: Correlation = 0.04, P-value = 4.020e-01\n",
      "famsup: Correlation = 0.04, P-value = 4.377e-01\n",
      "absences: Correlation = 0.03, P-value = 4.973e-01\n",
      "activities: Correlation = 0.02, P-value = 7.497e-01\n",
      "freetime: Correlation = 0.01, P-value = 8.227e-01\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr, pointbiserialr\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Specify the target column\n",
    "target_column = 'G3'  # Target column name\n",
    "\n",
    "# Separate numerical and categorical columns\n",
    "numerical_features = math.select_dtypes(include=['number']).columns\n",
    "categorical_features = math.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Dictionary to store correlation results\n",
    "correlation_results = {}\n",
    "\n",
    "# Handle numerical columns\n",
    "for col in numerical_features:\n",
    "    if col != target_column:\n",
    "        correlation, p_value = pearsonr(math[col], math[target_column])\n",
    "        correlation_results[col] = {'correlation': abs(correlation), 'p_value': p_value}\n",
    "\n",
    "# Handle categorical columns\n",
    "for col in categorical_features:\n",
    "    if col != target_column:\n",
    "        # Encode categorical values\n",
    "        encoded_col = LabelEncoder().fit_transform(math[col])\n",
    "        correlation, p_value = pointbiserialr(encoded_col, math[target_column])\n",
    "        correlation_results[col] = {'correlation': abs(correlation), 'p_value': p_value}\n",
    "\n",
    "# Sort features by correlation\n",
    "sorted_features = sorted(correlation_results.items(), key=lambda x: x[1]['correlation'], reverse=True)\n",
    "\n",
    "# Display top features with p-values\n",
    "print(\"Feature Correlations and P-values with Target Variable:\")\n",
    "for feature, stats in sorted_features:\n",
    "    print(f\"{feature}: Correlation = {stats['correlation']:.2f}, P-value = {stats['p_value']:.3e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance from Support Vector Regression (SVR):\n",
      "G2: 0.9909\n",
      "nursery: 0.0749\n",
      "famrel: 0.0692\n",
      "famsize: 0.0583\n",
      "romantic: 0.0537\n",
      "famsup: 0.0513\n",
      "schoolsup: 0.0485\n",
      "sex: 0.0429\n",
      "internet: 0.0422\n",
      "activities: 0.0404\n",
      "studytime: 0.0381\n",
      "Walc: 0.0381\n",
      "Medu: 0.0350\n",
      "Dalc: 0.0335\n",
      "Fedu: 0.0258\n",
      "goout: 0.0234\n",
      "address: 0.0231\n",
      "G1: 0.0198\n",
      "paid: 0.0188\n",
      "age: 0.0188\n",
      "guardian: 0.0133\n",
      "Pstatus: 0.0109\n",
      "failures: 0.0104\n",
      "Mjob: 0.0090\n",
      "health: 0.0085\n",
      "traveltime: 0.0070\n",
      "freetime: 0.0068\n",
      "higher: 0.0060\n",
      "reason: 0.0052\n",
      "school: 0.0050\n",
      "absences: 0.0049\n",
      "Fjob: 0.0014\n",
      "[[ 1.41e+01  1.40e+01]\n",
      " [ 1.11e+01  1.00e+01]\n",
      " [ 9.92e+00  9.00e+00]\n",
      " [ 1.53e+01  1.50e+01]\n",
      " [ 1.61e+01  1.60e+01]\n",
      " [ 1.20e+01  1.20e+01]\n",
      " [ 1.28e+01  1.40e+01]\n",
      " [ 1.09e+01  1.10e+01]\n",
      " [ 8.89e+00  9.00e+00]\n",
      " [ 1.50e+01  1.50e+01]\n",
      " [ 7.98e+00  1.00e+01]\n",
      " [ 1.22e+01  1.10e+01]\n",
      " [ 1.11e+01  1.00e+01]\n",
      " [ 8.13e+00  8.00e+00]\n",
      " [ 1.51e+01  1.50e+01]\n",
      " [ 1.42e+01  1.40e+01]\n",
      " [ 1.30e+01  1.20e+01]\n",
      " [ 9.88e+00  0.00e+00]\n",
      " [ 9.10e+00  1.00e+01]\n",
      " [ 1.50e+01  1.60e+01]\n",
      " [ 7.03e+00  0.00e+00]\n",
      " [ 4.77e+00  0.00e+00]\n",
      " [ 7.01e+00  8.00e+00]\n",
      " [ 1.50e+01  1.60e+01]\n",
      " [ 1.22e+01  1.20e+01]\n",
      " [ 1.59e+01  1.50e+01]\n",
      " [ 1.00e+01  1.00e+01]\n",
      " [ 1.91e+01  1.90e+01]\n",
      " [ 6.95e-02  0.00e+00]\n",
      " [ 1.31e+01  1.40e+01]\n",
      " [ 4.32e-03  0.00e+00]\n",
      " [ 7.91e+00  1.00e+01]\n",
      " [ 8.11e+00  8.00e+00]\n",
      " [ 5.91e+00  4.00e+00]\n",
      " [ 1.32e+01  1.30e+01]\n",
      " [ 1.02e+01  1.00e+01]\n",
      " [ 1.31e+01  1.30e+01]\n",
      " [ 1.82e+01  1.80e+01]\n",
      " [ 9.04e+00  8.00e+00]\n",
      " [ 1.20e+01  1.10e+01]\n",
      " [ 5.11e+00  6.00e+00]\n",
      " [ 1.82e+01  1.80e+01]\n",
      " [ 7.73e+00  8.00e+00]\n",
      " [ 8.95e+00  8.00e+00]\n",
      " [ 1.01e+01  1.10e+01]\n",
      " [-1.72e-01  0.00e+00]\n",
      " [ 1.20e+01  1.30e+01]\n",
      " [ 4.95e+00  0.00e+00]\n",
      " [ 1.21e+01  1.30e+01]\n",
      " [ 8.01e+00  7.00e+00]\n",
      " [ 9.21e+00  1.00e+01]\n",
      " [ 1.82e+01  1.80e+01]\n",
      " [ 1.12e+01  1.00e+01]\n",
      " [ 7.98e+00  9.00e+00]\n",
      " [ 1.21e+01  1.10e+01]\n",
      " [ 8.07e+00  6.00e+00]\n",
      " [ 8.99e+00  9.00e+00]\n",
      " [ 1.29e+01  1.30e+01]\n",
      " [ 1.50e+01  1.50e+01]\n",
      " [ 1.40e+01  1.40e+01]\n",
      " [ 1.31e+01  1.40e+01]\n",
      " [ 1.32e+01  1.50e+01]\n",
      " [ 1.41e+01  1.40e+01]\n",
      " [ 1.53e+01  1.50e+01]\n",
      " [ 8.94e+00  0.00e+00]\n",
      " [ 1.53e+01  1.50e+01]\n",
      " [ 1.81e+01  1.90e+01]\n",
      " [ 1.19e+01  1.20e+01]\n",
      " [ 5.01e+00  6.00e+00]\n",
      " [ 9.11e+00  9.00e+00]\n",
      " [ 9.05e+00  8.00e+00]\n",
      " [ 1.41e+01  1.50e+01]\n",
      " [ 6.88e+00  5.00e+00]\n",
      " [ 4.71e+00  0.00e+00]\n",
      " [ 9.37e+00  9.00e+00]\n",
      " [ 8.98e+00  0.00e+00]\n",
      " [ 1.10e+01  1.10e+01]\n",
      " [ 1.80e+01  1.80e+01]\n",
      " [ 6.94e+00  0.00e+00]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Encode categorical columns (if any)\n",
    "df_encoded = math.copy()\n",
    "for col in categorical_features:\n",
    "    df_encoded[col] = LabelEncoder().fit_transform(df_encoded[col])\n",
    "\n",
    "# Define the target column and features\n",
    "X = df_encoded.drop(columns=[\"G3\"])\n",
    "y = df_encoded[target_column]\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Initialize Support Vector Regression (SVR) with linear kernel\n",
    "regressor = SVR(kernel='linear')\n",
    "\n",
    "# Fit the model\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Get coefficients (this will only work if you're using a linear kernel)\n",
    "importances = abs(regressor.coef_).flatten()  # Flattening in case of multiple dimensions\n",
    "\n",
    "# Sort features by importance\n",
    "sorted_idx = importances.argsort()\n",
    "\n",
    "# Display feature importance\n",
    "print(\"Feature Importance from Support Vector Regression (SVR):\")\n",
    "for idx in sorted_idx[::-1]:  # Sorting in descending order\n",
    "    print(f\"{X.columns[idx]}: {importances[idx]:.4f}\")\n",
    "\n",
    "# Predict using the test data\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# Display predictions vs actual values\n",
    "np.set_printoptions(precision=2)  # Display only 2 decimals after the column for the numerical values\n",
    "comparison = np.concatenate((y_pred.reshape(len(y_pred), 1), y_test.values.reshape(len(y_test), 1)), axis=1)  # Fixed the axis argument\n",
    "print(comparison)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7806765535095334"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the model performance\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14.03 14.  ]\n",
      " [11.03 10.  ]\n",
      " [10.03  9.  ]\n",
      " [15.17 15.  ]\n",
      " [16.03 16.  ]\n",
      " [12.03 12.  ]\n",
      " [12.97 14.  ]\n",
      " [10.9  11.  ]\n",
      " [ 9.03  9.  ]\n",
      " [15.03 15.  ]\n",
      " [ 8.03 10.  ]\n",
      " [12.03 11.  ]\n",
      " [10.97 10.  ]\n",
      " [ 8.1   8.  ]\n",
      " [15.1  15.  ]\n",
      " [14.1  14.  ]\n",
      " [13.03 12.  ]\n",
      " [10.03  0.  ]\n",
      " [ 9.1  10.  ]\n",
      " [15.03 16.  ]\n",
      " [ 7.1   0.  ]\n",
      " [ 4.97  0.  ]\n",
      " [ 7.03  8.  ]\n",
      " [15.03 16.  ]\n",
      " [12.17 12.  ]\n",
      " [15.9  15.  ]\n",
      " [10.03 10.  ]\n",
      " [19.03 19.  ]\n",
      " [ 0.03  0.  ]\n",
      " [13.1  14.  ]\n",
      " [ 0.1   0.  ]\n",
      " [ 8.03 10.  ]\n",
      " [ 8.1   8.  ]\n",
      " [ 5.97  4.  ]\n",
      " [13.03 13.  ]\n",
      " [10.1  10.  ]\n",
      " [13.17 13.  ]\n",
      " [17.97 18.  ]\n",
      " [ 8.97  8.  ]\n",
      " [12.1  11.  ]\n",
      " [ 5.1   6.  ]\n",
      " [18.03 18.  ]\n",
      " [ 7.9   8.  ]\n",
      " [ 9.1   8.  ]\n",
      " [10.1  11.  ]\n",
      " [ 0.03  0.  ]\n",
      " [12.03 13.  ]\n",
      " [ 5.03  0.  ]\n",
      " [12.1  13.  ]\n",
      " [ 8.17  7.  ]\n",
      " [ 9.1  10.  ]\n",
      " [18.1  18.  ]\n",
      " [11.17 10.  ]\n",
      " [ 7.97  9.  ]\n",
      " [12.03 11.  ]\n",
      " [ 8.17  6.  ]\n",
      " [ 9.03  9.  ]\n",
      " [12.97 13.  ]\n",
      " [15.03 15.  ]\n",
      " [14.1  14.  ]\n",
      " [13.1  14.  ]\n",
      " [13.17 15.  ]\n",
      " [14.03 14.  ]\n",
      " [15.03 15.  ]\n",
      " [ 9.03  0.  ]\n",
      " [15.17 15.  ]\n",
      " [18.03 19.  ]\n",
      " [12.03 12.  ]\n",
      " [ 5.03  6.  ]\n",
      " [ 9.1   9.  ]\n",
      " [ 9.1   8.  ]\n",
      " [14.03 15.  ]\n",
      " [ 7.03  5.  ]\n",
      " [ 4.83  0.  ]\n",
      " [ 9.03  9.  ]\n",
      " [ 8.9   0.  ]\n",
      " [11.03 11.  ]\n",
      " [18.1  18.  ]\n",
      " [ 6.97  0.  ]]\n"
     ]
    }
   ],
   "source": [
    "# Select the top features based on importance (e.g., top 5 features)\n",
    "top_features_idx = importances.argsort()[::-1][:5]  # Top 5 features based on importance\n",
    "\n",
    "# Filter the dataset to use only the selected features\n",
    "X_selected_train = X_train.iloc[:, top_features_idx]\n",
    "X_selected_test = X_test.iloc[:, top_features_idx]\n",
    "\n",
    "# Train the model with only the selected features\n",
    "regressor.fit(X_selected_train, y_train)\n",
    "\n",
    "# Predict using the test data with selected features\n",
    "y_pred = regressor.predict(X_selected_test)\n",
    "\n",
    "# Display predictions vs actual values\n",
    "np.set_printoptions(precision=2)  # Display only 2 decimals after the column for the numerical values\n",
    "comparison = np.concatenate((y_pred.reshape(len(y_pred), 1), y_test.values.reshape(len(y_test), 1)), axis=1)\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77675217920871"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the model performance\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance from Support Vector Regression (SVR):\n",
      "G3: 0.9816\n",
      "schoolsup: 0.0206\n",
      "G2: 0.0189\n",
      "activities: 0.0085\n",
      "famsup: 0.0080\n",
      "nursery: 0.0044\n",
      "Dalc: 0.0037\n",
      "failures: 0.0033\n",
      "absences: 0.0029\n",
      "Medu: 0.0024\n",
      "sex: 0.0009\n",
      "Walc: 0.0008\n",
      "Mjob: 0.0007\n",
      "G1: 0.0006\n",
      "higher: 0.0000\n",
      "[[ 1.40e+01  1.40e+01]\n",
      " [ 9.94e+00  1.00e+01]\n",
      " [ 8.97e+00  9.00e+00]\n",
      " [ 1.49e+01  1.50e+01]\n",
      " [ 1.59e+01  1.60e+01]\n",
      " [ 1.20e+01  1.20e+01]\n",
      " [ 1.39e+01  1.40e+01]\n",
      " [ 1.09e+01  1.10e+01]\n",
      " [ 8.95e+00  9.00e+00]\n",
      " [ 1.49e+01  1.50e+01]\n",
      " [ 9.91e+00  1.00e+01]\n",
      " [ 1.11e+01  1.10e+01]\n",
      " [ 9.98e+00  1.00e+01]\n",
      " [ 7.98e+00  8.00e+00]\n",
      " [ 1.50e+01  1.50e+01]\n",
      " [ 1.39e+01  1.40e+01]\n",
      " [ 1.20e+01  1.20e+01]\n",
      " [ 1.10e-01  0.00e+00]\n",
      " [ 9.93e+00  1.00e+01]\n",
      " [ 1.59e+01  1.60e+01]\n",
      " [ 6.62e-02  0.00e+00]\n",
      " [ 1.65e-02  0.00e+00]\n",
      " [ 7.91e+00  8.00e+00]\n",
      " [ 1.59e+01  1.60e+01]\n",
      " [ 1.19e+01  1.20e+01]\n",
      " [ 1.50e+01  1.50e+01]\n",
      " [ 9.94e+00  1.00e+01]\n",
      " [ 1.90e+01  1.90e+01]\n",
      " [-7.99e-02  0.00e+00]\n",
      " [ 1.39e+01  1.40e+01]\n",
      " [-8.28e-02  0.00e+00]\n",
      " [ 9.91e+00  1.00e+01]\n",
      " [ 7.93e+00  8.00e+00]\n",
      " [ 4.02e+00  4.00e+00]\n",
      " [ 1.29e+01  1.30e+01]\n",
      " [ 1.00e+01  1.00e+01]\n",
      " [ 1.29e+01  1.30e+01]\n",
      " [ 1.80e+01  1.80e+01]\n",
      " [ 7.96e+00  8.00e+00]\n",
      " [ 1.10e+01  1.10e+01]\n",
      " [ 5.93e+00  6.00e+00]\n",
      " [ 1.80e+01  1.80e+01]\n",
      " [ 7.98e+00  8.00e+00]\n",
      " [ 7.95e+00  8.00e+00]\n",
      " [ 1.09e+01  1.10e+01]\n",
      " [-8.36e-02  0.00e+00]\n",
      " [ 1.30e+01  1.30e+01]\n",
      " [ 2.85e-02  0.00e+00]\n",
      " [ 1.29e+01  1.30e+01]\n",
      " [ 6.94e+00  7.00e+00]\n",
      " [ 9.94e+00  1.00e+01]\n",
      " [ 1.79e+01  1.80e+01]\n",
      " [ 9.96e+00  1.00e+01]\n",
      " [ 8.91e+00  9.00e+00]\n",
      " [ 1.10e+01  1.10e+01]\n",
      " [ 6.00e+00  6.00e+00]\n",
      " [ 8.98e+00  9.00e+00]\n",
      " [ 1.29e+01  1.30e+01]\n",
      " [ 1.50e+01  1.50e+01]\n",
      " [ 1.39e+01  1.40e+01]\n",
      " [ 1.39e+01  1.40e+01]\n",
      " [ 1.49e+01  1.50e+01]\n",
      " [ 1.39e+01  1.40e+01]\n",
      " [ 1.50e+01  1.50e+01]\n",
      " [ 1.02e-01  0.00e+00]\n",
      " [ 1.50e+01  1.50e+01]\n",
      " [ 1.89e+01  1.90e+01]\n",
      " [ 1.19e+01  1.20e+01]\n",
      " [ 5.95e+00  6.00e+00]\n",
      " [ 8.94e+00  9.00e+00]\n",
      " [ 7.98e+00  8.00e+00]\n",
      " [ 1.49e+01  1.50e+01]\n",
      " [ 5.00e+00  5.00e+00]\n",
      " [ 2.25e-02  0.00e+00]\n",
      " [ 9.16e+00  9.00e+00]\n",
      " [ 1.17e-01  0.00e+00]\n",
      " [ 1.09e+01  1.10e+01]\n",
      " [ 1.79e+01  1.80e+01]\n",
      " [ 4.88e-02  0.00e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Encode categorical columns (if any)\n",
    "df_encoded = math.copy()\n",
    "\n",
    "numerical_features = math.select_dtypes(include=['number']).columns\n",
    "categorical_features = math.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "for col in categorical_features:\n",
    "    df_encoded[col] = LabelEncoder().fit_transform(df_encoded[col])\n",
    "\n",
    "# Define the target column and features\n",
    "X = df_encoded[['G3', 'Medu', 'failures', 'Dalc', 'Walc', 'absences', 'G1', 'G2', 'sex', 'Mjob', 'schoolsup', 'famsup', 'activities', 'nursery', 'higher']]\n",
    "y = df_encoded[target_column]\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Initialize Support Vector Regression (SVR) with linear kernel\n",
    "regressor = SVR(kernel='linear')\n",
    "\n",
    "# Fit the model\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Get coefficients (this will only work if you're using a linear kernel)\n",
    "importances = abs(regressor.coef_).flatten()  # Flattening in case of multiple dimensions\n",
    "\n",
    "# Sort features by importance\n",
    "sorted_idx = importances.argsort()\n",
    "\n",
    "# Display feature importance\n",
    "print(\"Feature Importance from Support Vector Regression (SVR):\")\n",
    "for idx in sorted_idx[::-1]:  # Sorting in descending order\n",
    "    print(f\"{X.columns[idx]}: {importances[idx]:.4f}\")\n",
    "\n",
    "# Predict using the test data\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# Display predictions vs actual values\n",
    "np.set_printoptions(precision=2)  # Display only 2 decimals after the column for the numerical values\n",
    "comparison = np.concatenate((y_pred.reshape(len(y_pred), 1), y_test.values.reshape(len(y_test), 1)), axis=1)  # Fixed the axis argument\n",
    "print(comparison)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998576191201302"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the model performance\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
