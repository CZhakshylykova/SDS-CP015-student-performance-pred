{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr, pointbiserialr\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the data set\n",
    "# Import the dataset\n",
    "math = pd.read_csv(\"./student-mat.csv\", sep=';', header=0)\n",
    "por = pd.read_csv(\"./student-por.csv\", sep=';', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Correlations and P-values with Target Variable:\n",
      "G2: Correlation = 0.90, P-value = 7.626e-148\n",
      "G1: Correlation = 0.80, P-value = 9.001e-90\n",
      "failures: Correlation = 0.36, P-value = 1.466e-13\n",
      "Medu: Correlation = 0.22, P-value = 1.336e-05\n",
      "higher: Correlation = 0.18, P-value = 2.668e-04\n",
      "age: Correlation = 0.16, P-value = 1.271e-03\n",
      "Fedu: Correlation = 0.15, P-value = 2.380e-03\n",
      "goout: Correlation = 0.13, P-value = 8.229e-03\n",
      "romantic: Correlation = 0.13, P-value = 9.713e-03\n",
      "reason: Correlation = 0.12, P-value = 1.527e-02\n",
      "traveltime: Correlation = 0.12, P-value = 1.987e-02\n",
      "address: Correlation = 0.11, P-value = 3.563e-02\n",
      "sex: Correlation = 0.10, P-value = 3.987e-02\n",
      "Mjob: Correlation = 0.10, P-value = 4.259e-02\n",
      "paid: Correlation = 0.10, P-value = 4.277e-02\n",
      "internet: Correlation = 0.10, P-value = 5.048e-02\n",
      "studytime: Correlation = 0.10, P-value = 5.206e-02\n",
      "schoolsup: Correlation = 0.08, P-value = 1.004e-01\n",
      "famsize: Correlation = 0.08, P-value = 1.062e-01\n",
      "guardian: Correlation = 0.07, P-value = 1.643e-01\n",
      "health: Correlation = 0.06, P-value = 2.239e-01\n",
      "Pstatus: Correlation = 0.06, P-value = 2.501e-01\n",
      "Dalc: Correlation = 0.05, P-value = 2.785e-01\n",
      "Walc: Correlation = 0.05, P-value = 3.032e-01\n",
      "nursery: Correlation = 0.05, P-value = 3.066e-01\n",
      "famrel: Correlation = 0.05, P-value = 3.086e-01\n",
      "school: Correlation = 0.05, P-value = 3.722e-01\n",
      "Fjob: Correlation = 0.04, P-value = 4.020e-01\n",
      "famsup: Correlation = 0.04, P-value = 4.377e-01\n",
      "absences: Correlation = 0.03, P-value = 4.973e-01\n",
      "activities: Correlation = 0.02, P-value = 7.497e-01\n",
      "freetime: Correlation = 0.01, P-value = 8.227e-01\n"
     ]
    }
   ],
   "source": [
    "#feature selection \n",
    "\n",
    "from scipy.stats import pearsonr, pointbiserialr\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Specify the target column\n",
    "target_column = 'G3'  # Target column name\n",
    "\n",
    "# Separate numerical and categorical columns\n",
    "numerical_features = math.select_dtypes(include=['number']).columns\n",
    "categorical_features = math.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Dictionary to store correlation results\n",
    "correlation_results = {}\n",
    "\n",
    "# Handle numerical columns\n",
    "for col in numerical_features:\n",
    "    if col != target_column:\n",
    "        correlation, p_value = pearsonr(math[col], math[target_column])\n",
    "        correlation_results[col] = {'correlation': abs(correlation), 'p_value': p_value}\n",
    "\n",
    "# Handle categorical columns\n",
    "for col in categorical_features:\n",
    "    if col != target_column:\n",
    "        # Encode categorical values\n",
    "        encoded_col = LabelEncoder().fit_transform(math[col])\n",
    "        correlation, p_value = pointbiserialr(encoded_col, math[target_column])\n",
    "        correlation_results[col] = {'correlation': abs(correlation), 'p_value': p_value}\n",
    "\n",
    "# Sort features by correlation\n",
    "sorted_features = sorted(correlation_results.items(), key=lambda x: x[1]['correlation'], reverse=True)\n",
    "\n",
    "# Display top features with p-values\n",
    "print(\"Feature Correlations and P-values with Target Variable:\")\n",
    "for feature, stats in sorted_features:\n",
    "    print(f\"{feature}: Correlation = {stats['correlation']:.2f}, P-value = {stats['p_value']:.3e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance from Random Forest:\n",
      "       Feature  Importance\n",
      "31          G2    0.782230\n",
      "29    absences    0.111876\n",
      "2          age    0.020800\n",
      "23      famrel    0.008860\n",
      "10      reason    0.008789\n",
      "30          G1    0.007537\n",
      "25       goout    0.006726\n",
      "15   schoolsup    0.005189\n",
      "28      health    0.004268\n",
      "22    romantic    0.004108\n",
      "27        Walc    0.003926\n",
      "8         Mjob    0.003904\n",
      "14    failures    0.003863\n",
      "9         Fjob    0.003418\n",
      "24    freetime    0.003360\n",
      "7         Fedu    0.003133\n",
      "18  activities    0.002992\n",
      "11    guardian    0.002925\n",
      "13   studytime    0.002257\n",
      "6         Medu    0.001780\n",
      "12  traveltime    0.001523\n",
      "4      famsize    0.000889\n",
      "1          sex    0.000810\n",
      "3      address    0.000800\n",
      "17        paid    0.000797\n",
      "26        Dalc    0.000746\n",
      "20      higher    0.000722\n",
      "21    internet    0.000420\n",
      "0       school    0.000405\n",
      "16      famsup    0.000397\n",
      "19     nursery    0.000345\n",
      "5      Pstatus    0.000205\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'math' is your DataFrame and 'G3' is the target column\n",
    "target_column = 'G3'\n",
    "\n",
    "# Encode categorical columns (if any)\n",
    "df_encoded = math.copy()\n",
    "for col in categorical_features:\n",
    "    df_encoded[col] = LabelEncoder().fit_transform(df_encoded[col])\n",
    "\n",
    "# Separate features and target\n",
    "X = df_encoded.drop(columns=[target_column])\n",
    "y = df_encoded[target_column]\n",
    "\n",
    "# Handle categorical features with encoding\n",
    "X_encoded = pd.get_dummies(X, drop_first=True)  # One-hot encoding for categorical features\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit Random Forest Regressor\n",
    "regressor = RandomForestRegressor(random_state=0, n_estimators=30)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "importances = regressor.feature_importances_\n",
    "\n",
    "# Map feature names to their importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X_encoded.columns,\n",
    "    'Importance': importances\n",
    "})\n",
    "\n",
    "# Sort features by importance\n",
    "feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display top features\n",
    "print(\"Feature Importance from Random Forest:\")\n",
    "print(feature_importance)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using the test data\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.5  10.  ]\n",
      " [11.9  12.  ]\n",
      " [ 6.87  5.  ]\n",
      " [ 9.57 10.  ]\n",
      " [ 9.07  9.  ]\n",
      " [12.63 13.  ]\n",
      " [18.87 18.  ]\n",
      " [ 7.03  6.  ]\n",
      " [ 6.53  0.  ]\n",
      " [13.4  14.  ]\n",
      " [15.7  15.  ]\n",
      " [ 6.63  7.  ]\n",
      " [14.27 15.  ]\n",
      " [11.77 10.  ]\n",
      " [14.07 14.  ]\n",
      " [ 8.4   8.  ]\n",
      " [ 3.1   8.  ]\n",
      " [10.5  11.  ]\n",
      " [15.2  15.  ]\n",
      " [ 5.1   0.  ]\n",
      " [13.97 14.  ]\n",
      " [15.73 16.  ]\n",
      " [15.27 16.  ]\n",
      " [ 6.53  6.  ]\n",
      " [ 8.63  0.  ]\n",
      " [18.37 19.  ]\n",
      " [10.4  11.  ]\n",
      " [ 8.2  12.  ]\n",
      " [17.97 17.  ]\n",
      " [10.63 10.  ]\n",
      " [ 8.3   8.  ]\n",
      " [ 8.33 10.  ]\n",
      " [15.5  15.  ]\n",
      " [13.1  13.  ]\n",
      " [ 2.23  8.  ]\n",
      " [ 6.73  5.  ]\n",
      " [ 0.    0.  ]\n",
      " [15.03 15.  ]\n",
      " [11.77 14.  ]\n",
      " [ 7.97  8.  ]\n",
      " [ 6.2   5.  ]\n",
      " [ 9.97 11.  ]\n",
      " [13.97 14.  ]\n",
      " [ 9.    9.  ]\n",
      " [15.   15.  ]\n",
      " [ 9.17 10.  ]\n",
      " [11.73 11.  ]\n",
      " [14.2  13.  ]\n",
      " [12.93 13.  ]\n",
      " [15.67 16.  ]\n",
      " [13.1  13.  ]\n",
      " [15.5  15.  ]\n",
      " [10.47 12.  ]\n",
      " [ 8.9  10.  ]\n",
      " [ 5.97  6.  ]\n",
      " [13.13 12.  ]\n",
      " [10.5  11.  ]\n",
      " [ 3.    0.  ]\n",
      " [15.4  16.  ]\n",
      " [16.17 17.  ]\n",
      " [13.67 14.  ]\n",
      " [ 9.1  10.  ]\n",
      " [ 8.6  10.  ]\n",
      " [ 6.93  6.  ]\n",
      " [ 7.53  9.  ]\n",
      " [18.   17.  ]\n",
      " [ 8.97  8.  ]\n",
      " [ 9.83 10.  ]\n",
      " [ 9.5   9.  ]\n",
      " [15.4  15.  ]\n",
      " [ 8.2   6.  ]\n",
      " [ 9.9  10.  ]\n",
      " [13.6  15.  ]\n",
      " [18.23 19.  ]\n",
      " [10.17 12.  ]\n",
      " [ 6.    6.  ]\n",
      " [ 9.1   9.  ]\n",
      " [14.37 15.  ]\n",
      " [ 5.83  5.  ]]\n"
     ]
    }
   ],
   "source": [
    "# Display predictions vs actual values\n",
    "np.set_printoptions(precision=2)  # Display only 2 decimals after the column for the numerical values\n",
    "comparison = np.concatenate((y_pred.reshape(len(y_pred), 1), y_test.values.reshape(len(y_test), 1)), axis=1)  # Fixed the axis argument\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8253704282534027"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the model performance\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance from Random Forest:\n",
      "       Feature  Importance\n",
      "0           G3    0.993123\n",
      "5     absences    0.005914\n",
      "7           G2    0.000674\n",
      "2     failures    0.000094\n",
      "4         Walc    0.000053\n",
      "1         Medu    0.000045\n",
      "9         Mjob    0.000037\n",
      "12  activities    0.000027\n",
      "11      famsup    0.000015\n",
      "6           G1    0.000009\n",
      "8          sex    0.000009\n",
      "3         Dalc    0.000000\n",
      "10   schoolsup    0.000000\n",
      "13     nursery    0.000000\n",
      "14      higher    0.000000\n"
     ]
    }
   ],
   "source": [
    "# Encode categorical columns (if any)\n",
    "df_encoded = math.copy()\n",
    "\n",
    "numerical_features = math.select_dtypes(include=['number']).columns\n",
    "categorical_features = math.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "for col in categorical_features:\n",
    "    df_encoded[col] = LabelEncoder().fit_transform(df_encoded[col])\n",
    "\n",
    "# Define the target column and features\n",
    "X = df_encoded[['G3', 'Medu', 'failures', 'Dalc', 'Walc', 'absences', 'G1', 'G2', 'sex', 'Mjob', 'schoolsup', 'famsup', 'activities', 'nursery', 'higher']]\n",
    "y = df_encoded[target_column]\n",
    "\n",
    "# Handle categorical features with encoding\n",
    "X_encoded = pd.get_dummies(X, drop_first=True)  # One-hot encoding for categorical features\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit Random Forest Regressor\n",
    "regressor = RandomForestRegressor(random_state=0, n_estimators=30)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "importances = regressor.feature_importances_\n",
    "\n",
    "# Map feature names to their importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X_encoded.columns,\n",
    "    'Importance': importances\n",
    "})\n",
    "\n",
    "# Sort features by importance\n",
    "feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display top features\n",
    "print(\"Feature Importance from Random Forest:\")\n",
    "print(feature_importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using the test data\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9997901103366361"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the model performance\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
