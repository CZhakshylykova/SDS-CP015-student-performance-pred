{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no need for the feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr, pointbiserialr\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the data set\n",
    "# Import the dataset\n",
    "math = pd.read_csv(\"./student-mat.csv\", sep=';', header=0)\n",
    "por = pd.read_csv(\"./student-por.csv\", sep=';', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Correlations and P-values with Target Variable:\n",
      "G2: Correlation = 0.90, P-value = 7.626e-148\n",
      "G1: Correlation = 0.80, P-value = 9.001e-90\n",
      "failures: Correlation = 0.36, P-value = 1.466e-13\n",
      "Medu: Correlation = 0.22, P-value = 1.336e-05\n",
      "higher: Correlation = 0.18, P-value = 2.668e-04\n",
      "age: Correlation = 0.16, P-value = 1.271e-03\n",
      "Fedu: Correlation = 0.15, P-value = 2.380e-03\n",
      "goout: Correlation = 0.13, P-value = 8.229e-03\n",
      "romantic: Correlation = 0.13, P-value = 9.713e-03\n",
      "reason: Correlation = 0.12, P-value = 1.527e-02\n",
      "traveltime: Correlation = 0.12, P-value = 1.987e-02\n",
      "address: Correlation = 0.11, P-value = 3.563e-02\n",
      "sex: Correlation = 0.10, P-value = 3.987e-02\n",
      "Mjob: Correlation = 0.10, P-value = 4.259e-02\n",
      "paid: Correlation = 0.10, P-value = 4.277e-02\n",
      "internet: Correlation = 0.10, P-value = 5.048e-02\n",
      "studytime: Correlation = 0.10, P-value = 5.206e-02\n",
      "schoolsup: Correlation = 0.08, P-value = 1.004e-01\n",
      "famsize: Correlation = 0.08, P-value = 1.062e-01\n",
      "guardian: Correlation = 0.07, P-value = 1.643e-01\n",
      "health: Correlation = 0.06, P-value = 2.239e-01\n",
      "Pstatus: Correlation = 0.06, P-value = 2.501e-01\n",
      "Dalc: Correlation = 0.05, P-value = 2.785e-01\n",
      "Walc: Correlation = 0.05, P-value = 3.032e-01\n",
      "nursery: Correlation = 0.05, P-value = 3.066e-01\n",
      "famrel: Correlation = 0.05, P-value = 3.086e-01\n",
      "school: Correlation = 0.05, P-value = 3.722e-01\n",
      "Fjob: Correlation = 0.04, P-value = 4.020e-01\n",
      "famsup: Correlation = 0.04, P-value = 4.377e-01\n",
      "absences: Correlation = 0.03, P-value = 4.973e-01\n",
      "activities: Correlation = 0.02, P-value = 7.497e-01\n",
      "freetime: Correlation = 0.01, P-value = 8.227e-01\n"
     ]
    }
   ],
   "source": [
    "#feature selection \n",
    "\n",
    "from scipy.stats import pearsonr, pointbiserialr\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Specify the target column\n",
    "target_column = 'G3'  # Target column name\n",
    "\n",
    "# Separate numerical and categorical columns\n",
    "numerical_features = math.select_dtypes(include=['number']).columns\n",
    "categorical_features = math.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Dictionary to store correlation results\n",
    "correlation_results = {}\n",
    "\n",
    "# Handle numerical columns\n",
    "for col in numerical_features:\n",
    "    if col != target_column:\n",
    "        correlation, p_value = pearsonr(math[col], math[target_column])\n",
    "        correlation_results[col] = {'correlation': abs(correlation), 'p_value': p_value}\n",
    "\n",
    "# Handle categorical columns\n",
    "for col in categorical_features:\n",
    "    if col != target_column:\n",
    "        # Encode categorical values\n",
    "        encoded_col = LabelEncoder().fit_transform(math[col])\n",
    "        correlation, p_value = pointbiserialr(encoded_col, math[target_column])\n",
    "        correlation_results[col] = {'correlation': abs(correlation), 'p_value': p_value}\n",
    "\n",
    "# Sort features by correlation\n",
    "sorted_features = sorted(correlation_results.items(), key=lambda x: x[1]['correlation'], reverse=True)\n",
    "\n",
    "# Display top features with p-values\n",
    "print(\"Feature Correlations and P-values with Target Variable:\")\n",
    "for feature, stats in sorted_features:\n",
    "    print(f\"{feature}: Correlation = {stats['correlation']:.2f}, P-value = {stats['p_value']:.3e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance from Random Forest:\n",
      "       Feature  Importance\n",
      "31          G2    0.835089\n",
      "29    absences    0.036838\n",
      "30          G1    0.023642\n",
      "2          age    0.008134\n",
      "16      famsup    0.007449\n",
      "26        Dalc    0.006803\n",
      "23      famrel    0.005973\n",
      "8         Mjob    0.005840\n",
      "27        Walc    0.005707\n",
      "28      health    0.005601\n",
      "0       school    0.005455\n",
      "24    freetime    0.005168\n",
      "12  traveltime    0.004902\n",
      "10      reason    0.004838\n",
      "25       goout    0.004790\n",
      "7         Fedu    0.004450\n",
      "6         Medu    0.003533\n",
      "11    guardian    0.003445\n",
      "14    failures    0.003154\n",
      "15   schoolsup    0.002635\n",
      "9         Fjob    0.002288\n",
      "18  activities    0.001928\n",
      "1          sex    0.001863\n",
      "13   studytime    0.001712\n",
      "21    internet    0.001666\n",
      "4      famsize    0.001596\n",
      "3      address    0.001123\n",
      "20      higher    0.001067\n",
      "22    romantic    0.001046\n",
      "19     nursery    0.000890\n",
      "17        paid    0.000820\n",
      "5      Pstatus    0.000553\n",
      "[[ 6.9   8.  ]\n",
      " [14.87 15.  ]\n",
      " [15.83 16.  ]\n",
      " [10.2  10.  ]\n",
      " [ 9.7  10.  ]\n",
      " [13.17 12.  ]\n",
      " [12.8  13.  ]\n",
      " [17.7  17.  ]\n",
      " [12.27 12.  ]\n",
      " [11.17 12.  ]\n",
      " [10.5  11.  ]\n",
      " [10.53 10.  ]\n",
      " [13.27 13.  ]\n",
      " [ 8.97  8.  ]\n",
      " [17.43 18.  ]\n",
      " [13.27 12.  ]\n",
      " [12.53 13.  ]\n",
      " [12.9  13.  ]\n",
      " [10.47 10.  ]\n",
      " [10.27 10.  ]\n",
      " [12.6  12.  ]\n",
      " [10.27 10.  ]\n",
      " [17.3  17.  ]\n",
      " [13.33 15.  ]\n",
      " [12.83 14.  ]\n",
      " [ 1.7   0.  ]\n",
      " [12.33 12.  ]\n",
      " [13.27 14.  ]\n",
      " [11.53 12.  ]\n",
      " [12.87  9.  ]\n",
      " [13.3  13.  ]\n",
      " [16.1  16.  ]\n",
      " [13.3  13.  ]\n",
      " [16.1  16.  ]\n",
      " [13.13 12.  ]\n",
      " [ 9.13 10.  ]\n",
      " [ 9.73 10.  ]\n",
      " [11.3  11.  ]\n",
      " [12.8  13.  ]\n",
      " [11.4  10.  ]\n",
      " [15.63 15.  ]\n",
      " [17.73 18.  ]\n",
      " [11.63 11.  ]\n",
      " [13.43 13.  ]\n",
      " [12.53 13.  ]\n",
      " [ 9.93 10.  ]\n",
      " [12.67 14.  ]\n",
      " [ 9.8   9.  ]\n",
      " [11.5  11.  ]\n",
      " [ 8.8  10.  ]\n",
      " [ 7.13  8.  ]\n",
      " [14.83 17.  ]\n",
      " [ 9.9   9.  ]\n",
      " [12.03 13.  ]\n",
      " [ 7.63  8.  ]\n",
      " [10.93 11.  ]\n",
      " [11.77 12.  ]\n",
      " [11.03 12.  ]\n",
      " [14.17 15.  ]\n",
      " [14.8  15.  ]\n",
      " [13.73 13.  ]\n",
      " [ 7.57  7.  ]\n",
      " [10.6  12.  ]\n",
      " [ 9.57 10.  ]\n",
      " [13.4  12.  ]\n",
      " [12.57 12.  ]\n",
      " [11.23 11.  ]\n",
      " [13.23 13.  ]\n",
      " [14.83 14.  ]\n",
      " [ 2.7   8.  ]\n",
      " [ 6.63  9.  ]\n",
      " [11.5  11.  ]\n",
      " [12.87 13.  ]\n",
      " [10.67 11.  ]\n",
      " [14.07 14.  ]\n",
      " [13.17 13.  ]\n",
      " [13.2  14.  ]\n",
      " [11.43 13.  ]\n",
      " [13.4  13.  ]\n",
      " [12.83 13.  ]\n",
      " [14.9  14.  ]\n",
      " [ 9.63 11.  ]\n",
      " [10.33 10.  ]\n",
      " [13.43 14.  ]\n",
      " [18.   17.  ]\n",
      " [11.33 13.  ]\n",
      " [10.33 10.  ]\n",
      " [13.37 12.  ]\n",
      " [13.4  13.  ]\n",
      " [13.1  10.  ]\n",
      " [11.53 12.  ]\n",
      " [15.73 16.  ]\n",
      " [17.17 17.  ]\n",
      " [11.87 11.  ]\n",
      " [ 8.07  6.  ]\n",
      " [10.2  11.  ]\n",
      " [13.4  14.  ]\n",
      " [10.9  11.  ]\n",
      " [13.37 13.  ]\n",
      " [14.37 15.  ]\n",
      " [12.57 14.  ]\n",
      " [ 8.93 10.  ]\n",
      " [ 7.83  8.  ]\n",
      " [11.33 11.  ]\n",
      " [10.   10.  ]\n",
      " [10.8  12.  ]\n",
      " [15.73 17.  ]\n",
      " [11.17 11.  ]\n",
      " [10.03  9.  ]\n",
      " [15.67 15.  ]\n",
      " [12.67 12.  ]\n",
      " [13.3  13.  ]\n",
      " [14.53 14.  ]\n",
      " [13.13 14.  ]\n",
      " [10.9  12.  ]\n",
      " [10.17 11.  ]\n",
      " [15.8  15.  ]\n",
      " [16.23 16.  ]\n",
      " [10.3  10.  ]\n",
      " [10.37 12.  ]\n",
      " [ 7.57  8.  ]\n",
      " [10.6  11.  ]\n",
      " [ 9.77 11.  ]\n",
      " [10.6  11.  ]\n",
      " [13.07 14.  ]\n",
      " [15.57 15.  ]\n",
      " [15.27 14.  ]\n",
      " [17.03 15.  ]\n",
      " [12.97 10.  ]\n",
      " [11.17 11.  ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8355617378556673"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# 'G3' is the target column\n",
    "target_column = 'G3'\n",
    "\n",
    "# Encode categorical columns (if any)\n",
    "df_encoded = por.copy()\n",
    "for col in categorical_features:\n",
    "    df_encoded[col] = LabelEncoder().fit_transform(df_encoded[col])\n",
    "\n",
    "# Separate features and target\n",
    "X = df_encoded.drop(columns=[target_column])\n",
    "y = df_encoded[target_column]\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Fit Random Forest Regressor\n",
    "regressor = RandomForestRegressor(random_state=0, n_estimators=30)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "importances = regressor.feature_importances_\n",
    "\n",
    "# Map feature names to their importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': importances\n",
    "})\n",
    "\n",
    "# Sort features by importance\n",
    "feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display top features\n",
    "print(\"Feature Importance from Random Forest:\")\n",
    "print(feature_importance)\n",
    "\n",
    "# Predict using the test data\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# Display predictions vs actual values\n",
    "np.set_printoptions(precision=2)  # Display only 2 decimals after the column for the numerical values\n",
    "comparison = np.concatenate((y_pred.reshape(len(y_pred), 1), y_test.values.reshape(len(y_test), 1)), axis=1)  # Fixed the axis argument\n",
    "print(comparison)\n",
    "\n",
    "# Evaluating the model performance\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "r2 is about 87% by n_estimators = 30, 84% by n_estimators = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR with selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance from Random Forest:\n",
      "       Feature  Importance\n",
      "0           G3    0.993123\n",
      "5     absences    0.005914\n",
      "7           G2    0.000674\n",
      "2     failures    0.000094\n",
      "4         Walc    0.000053\n",
      "1         Medu    0.000045\n",
      "9         Mjob    0.000037\n",
      "12  activities    0.000027\n",
      "11      famsup    0.000015\n",
      "6           G1    0.000009\n",
      "8          sex    0.000009\n",
      "3         Dalc    0.000000\n",
      "10   schoolsup    0.000000\n",
      "13     nursery    0.000000\n",
      "14      higher    0.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9997901103366361"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode categorical columns (if any)\n",
    "df_encoded = math.copy()\n",
    "\n",
    "numerical_features = por.select_dtypes(include=['number']).columns\n",
    "categorical_features = por.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "for col in categorical_features:\n",
    "    df_encoded[col] = LabelEncoder().fit_transform(df_encoded[col])\n",
    "\n",
    "# Define the target column and features\n",
    "X = df_encoded[['G3', 'Medu', 'failures', 'Dalc', 'Walc', 'absences', 'G1', 'G2', 'sex', 'Mjob', 'schoolsup', 'famsup', 'activities', 'nursery', 'higher']]\n",
    "y = df_encoded[target_column]\n",
    "\n",
    "# Handle categorical features with encoding\n",
    "#X_encoded = pd.get_dummies(X, drop_first=True)  # One-hot encoding for categorical features\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit Random Forest Regressor\n",
    "regressor = RandomForestRegressor(random_state=0, n_estimators=30)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "importances = regressor.feature_importances_\n",
    "\n",
    "# Map feature names to their importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': importances\n",
    "})\n",
    "\n",
    "# Sort features by importance\n",
    "feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display top features\n",
    "print(\"Feature Importance from Random Forest:\")\n",
    "print(feature_importance)\n",
    "\n",
    "\n",
    "# Predict using the test data\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "\n",
    "# Evaluating the model performance\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=30.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for each fold: [0.71 0.79 0.71 0.79 0.64 0.77 0.69 0.92 0.85 0.69 0.77 0.92 0.92 0.85\n",
      " 0.77 0.92 0.77 0.77 0.77 0.85 0.77 0.77 0.85 0.85 0.92 0.85 0.92 0.92\n",
      " 0.85 0.85]\n",
      "Average accuracy: 0.8137362637362638\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier  # Example model\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# Assuming X (features) and y (target) are already defined\n",
    "regressor = RandomForestClassifier(n_estimators=30, random_state = 0)\n",
    "\n",
    "# Perform K-fold Cross-Validation (e.g., 5 folds)\n",
    "cv_scores = cross_val_score(regressor, X, y, cv=30, scoring='accuracy')\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy for each fold: {cv_scores}\")\n",
    "print(f\"Average accuracy: {cv_scores.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation R² Scores: [0.87 0.83 0.9 ]\n",
      "Average Cross-validation R² Score: 0.8691\n",
      "Best Parameters from RandomizedSearchCV: {'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': 10}\n",
      "Best R² Score from RandomizedSearchCV: 0.8772\n",
      "R² Score on Test Set: 0.8449\n",
      "Feature Importance from Random Forest:\n",
      "       Feature  Importance\n",
      "6           G2    0.799906\n",
      "4     absences    0.121834\n",
      "8         Mjob    0.011487\n",
      "5           G1    0.011289\n",
      "3         Walc    0.010859\n",
      "9    schoolsup    0.010452\n",
      "1     failures    0.010067\n",
      "11  activities    0.007213\n",
      "0         Medu    0.004840\n",
      "12     nursery    0.003802\n",
      "2         Dalc    0.003374\n",
      "7          sex    0.002545\n",
      "10      famsup    0.001898\n",
      "13      higher    0.000432\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Encode categorical columns (if any)\n",
    "df_encoded = math.copy()\n",
    "\n",
    "# Apply Label Encoding to categorical features\n",
    "categorical_features = df_encoded.select_dtypes(include=['object', 'category']).columns\n",
    "for col in categorical_features:\n",
    "    df_encoded[col] = LabelEncoder().fit_transform(df_encoded[col])\n",
    "\n",
    "# Define the target column and features\n",
    "target_column = \"G3\"\n",
    "X = df_encoded[['Medu', 'failures', 'Dalc', 'Walc', 'absences', 'G1', 'G2', 'sex', 'Mjob', 'schoolsup', 'famsup', 'activities', 'nursery', 'higher']]\n",
    "y = df_encoded[target_column]\n",
    "\n",
    "# Split the data into training and testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# K-Fold Cross-Validation with RandomForest Regressor\n",
    "regressor = RandomForestRegressor(random_state=0, n_estimators=10, n_jobs=1)  # Set n_jobs=1 for debugging\n",
    "\n",
    "# Perform K-fold Cross Validation (e.g., 3 folds for debugging)\n",
    "cv_scores = cross_val_score(regressor, X_train, y_train, cv=3, scoring='r2')\n",
    "print(f\"Cross-validation R² Scores: {cv_scores}\")\n",
    "print(f\"Average Cross-validation R² Score: {cv_scores.mean():.4f}\")\n",
    "\n",
    "# Hyperparameter Tuning with RandomizedSearchCV\n",
    "# Define the parameter grid\n",
    "param_dist = {\n",
    "    'n_estimators': [10, 100],  # Reduced number of estimators for debugging\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# Perform RandomizedSearchCV with 3-fold cross-validation for debugging\n",
    "random_search = RandomizedSearchCV(estimator=regressor, param_distributions=param_dist, cv=3, scoring='r2', n_iter=5, random_state=42, n_jobs=1)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score from the RandomizedSearchCV\n",
    "print(f\"Best Parameters from RandomizedSearchCV: {random_search.best_params_}\")\n",
    "print(f\"Best R² Score from RandomizedSearchCV: {random_search.best_score_:.4f}\")\n",
    "\n",
    "# Train the model using the best parameters found by RandomizedSearchCV\n",
    "best_regressor = random_search.best_estimator_\n",
    "\n",
    "# Fit the model on the entire training set with the best parameters\n",
    "best_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the test data\n",
    "y_pred = best_regressor.predict(X_test)\n",
    "\n",
    "# Evaluating the model performance\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R² Score on Test Set: {r2:.4f}\")\n",
    "\n",
    "# Feature Importances\n",
    "importances = best_regressor.feature_importances_\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': importances\n",
    "})\n",
    "\n",
    "# Sort features by importance\n",
    "feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display top features\n",
    "print(\"Feature Importance from Random Forest:\")\n",
    "print(feature_importance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest performance (r2): \n",
    "with all features 0.8434608727973889 for math, 0.8253073565669354 for por\n",
    "with feature selection 0.9997901103366361 for math, 0.9994539641702332 for por\n",
    "with hyperparameter tuning  0.8449 for math, 0.8120 for por"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
